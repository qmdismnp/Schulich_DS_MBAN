{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mp\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://raw.githubusercontent.com/qmdismnp/Schulich_DS_MBAN/refs/heads/main/dataset.csv?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_date</th>\n",
       "      <th>requested_delivery_date</th>\n",
       "      <th>Customer Country Code</th>\n",
       "      <th>Product Code</th>\n",
       "      <th>Description</th>\n",
       "      <th>order_type</th>\n",
       "      <th>Customer Order Code</th>\n",
       "      <th>value</th>\n",
       "      <th>Curr</th>\n",
       "      <th>items</th>\n",
       "      <th>Route</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.07.2009</td>\n",
       "      <td>28.01.2010</td>\n",
       "      <td>RU</td>\n",
       "      <td>L10705000</td>\n",
       "      <td>Parka Outdoor Lifestyle STD</td>\n",
       "      <td>VO</td>\n",
       "      <td>3200435553</td>\n",
       "      <td>2337.00</td>\n",
       "      <td>RUB</td>\n",
       "      <td>6</td>\n",
       "      <td>RU0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.07.2009</td>\n",
       "      <td>24.03.2010</td>\n",
       "      <td>RU</td>\n",
       "      <td>L10705000</td>\n",
       "      <td>Parka Outdoor Lifestyle STD</td>\n",
       "      <td>VO</td>\n",
       "      <td>3200435694</td>\n",
       "      <td>10160.25</td>\n",
       "      <td>RUB</td>\n",
       "      <td>23</td>\n",
       "      <td>RU0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.07.2009</td>\n",
       "      <td>04.02.2010</td>\n",
       "      <td>RU</td>\n",
       "      <td>L10705000</td>\n",
       "      <td>Parka Outdoor Lifestyle STD</td>\n",
       "      <td>VO</td>\n",
       "      <td>3200435741</td>\n",
       "      <td>2992.50</td>\n",
       "      <td>RUB</td>\n",
       "      <td>7</td>\n",
       "      <td>RU0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.07.2009</td>\n",
       "      <td>04.02.2010</td>\n",
       "      <td>RU</td>\n",
       "      <td>L10705000</td>\n",
       "      <td>Parka Outdoor Lifestyle STD</td>\n",
       "      <td>VO</td>\n",
       "      <td>3200435907</td>\n",
       "      <td>4061.25</td>\n",
       "      <td>RUB</td>\n",
       "      <td>9</td>\n",
       "      <td>RU0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.07.2009</td>\n",
       "      <td>01.02.2010</td>\n",
       "      <td>RU</td>\n",
       "      <td>L10705000</td>\n",
       "      <td>Parka Outdoor Lifestyle STD</td>\n",
       "      <td>VO</td>\n",
       "      <td>3200435963</td>\n",
       "      <td>2208.75</td>\n",
       "      <td>RUB</td>\n",
       "      <td>5</td>\n",
       "      <td>RU0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2415</th>\n",
       "      <td>13.07.2011</td>\n",
       "      <td>15.02.2012</td>\n",
       "      <td>HR</td>\n",
       "      <td>L12919200</td>\n",
       "      <td>Parka Outdoor Lifestyle STD</td>\n",
       "      <td>VO</td>\n",
       "      <td>3200819196</td>\n",
       "      <td>128.52</td>\n",
       "      <td>EUR</td>\n",
       "      <td>12</td>\n",
       "      <td>FI0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2416</th>\n",
       "      <td>13.07.2011</td>\n",
       "      <td>15.02.2012</td>\n",
       "      <td>HR</td>\n",
       "      <td>L12919200</td>\n",
       "      <td>Parka Outdoor Lifestyle STD</td>\n",
       "      <td>VO</td>\n",
       "      <td>3200819201</td>\n",
       "      <td>128.52</td>\n",
       "      <td>EUR</td>\n",
       "      <td>12</td>\n",
       "      <td>FI0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417</th>\n",
       "      <td>13.07.2011</td>\n",
       "      <td>15.02.2012</td>\n",
       "      <td>HR</td>\n",
       "      <td>L12919200</td>\n",
       "      <td>Parka Outdoor Lifestyle STD</td>\n",
       "      <td>VO</td>\n",
       "      <td>3200819206</td>\n",
       "      <td>128.52</td>\n",
       "      <td>EUR</td>\n",
       "      <td>12</td>\n",
       "      <td>FI0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2418</th>\n",
       "      <td>13.07.2011</td>\n",
       "      <td>15.02.2012</td>\n",
       "      <td>HR</td>\n",
       "      <td>L12919200</td>\n",
       "      <td>Parka Outdoor Lifestyle STD</td>\n",
       "      <td>VO</td>\n",
       "      <td>3200819210</td>\n",
       "      <td>107.10</td>\n",
       "      <td>EUR</td>\n",
       "      <td>10</td>\n",
       "      <td>FI0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2419</th>\n",
       "      <td>23.01.2012</td>\n",
       "      <td>15.04.2012</td>\n",
       "      <td>RU</td>\n",
       "      <td>L12919200</td>\n",
       "      <td>Parka Outdoor Lifestyle STD</td>\n",
       "      <td>VO</td>\n",
       "      <td>3200828659</td>\n",
       "      <td>4183.00</td>\n",
       "      <td>RUB</td>\n",
       "      <td>10</td>\n",
       "      <td>RU0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2420 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      order_date requested_delivery_date Customer Country Code Product Code  \\\n",
       "0     13.07.2009              28.01.2010                    RU    L10705000   \n",
       "1     15.07.2009              24.03.2010                    RU    L10705000   \n",
       "2     16.07.2009              04.02.2010                    RU    L10705000   \n",
       "3     17.07.2009              04.02.2010                    RU    L10705000   \n",
       "4     21.07.2009              01.02.2010                    RU    L10705000   \n",
       "...          ...                     ...                   ...          ...   \n",
       "2415  13.07.2011              15.02.2012                    HR    L12919200   \n",
       "2416  13.07.2011              15.02.2012                    HR    L12919200   \n",
       "2417  13.07.2011              15.02.2012                    HR    L12919200   \n",
       "2418  13.07.2011              15.02.2012                    HR    L12919200   \n",
       "2419  23.01.2012              15.04.2012                    RU    L12919200   \n",
       "\n",
       "                      Description order_type  Customer Order Code     value  \\\n",
       "0     Parka Outdoor Lifestyle STD         VO           3200435553   2337.00   \n",
       "1     Parka Outdoor Lifestyle STD         VO           3200435694  10160.25   \n",
       "2     Parka Outdoor Lifestyle STD         VO           3200435741   2992.50   \n",
       "3     Parka Outdoor Lifestyle STD         VO           3200435907   4061.25   \n",
       "4     Parka Outdoor Lifestyle STD         VO           3200435963   2208.75   \n",
       "...                           ...        ...                  ...       ...   \n",
       "2415  Parka Outdoor Lifestyle STD         VO           3200819196    128.52   \n",
       "2416  Parka Outdoor Lifestyle STD         VO           3200819201    128.52   \n",
       "2417  Parka Outdoor Lifestyle STD         VO           3200819206    128.52   \n",
       "2418  Parka Outdoor Lifestyle STD         VO           3200819210    107.10   \n",
       "2419  Parka Outdoor Lifestyle STD         VO           3200828659   4183.00   \n",
       "\n",
       "     Curr items   Route  \n",
       "0     RUB     6  RU0001  \n",
       "1     RUB    23  RU0001  \n",
       "2     RUB     7  RU0001  \n",
       "3     RUB     9  RU0001  \n",
       "4     RUB     5  RU0001  \n",
       "...   ...   ...     ...  \n",
       "2415  EUR    12  FI0003  \n",
       "2416  EUR    12  FI0003  \n",
       "2417  EUR    12  FI0003  \n",
       "2418  EUR    10  FI0003  \n",
       "2419  RUB    10  RU0001  \n",
       "\n",
       "[2420 rows x 11 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing or invalid values\n",
    "data.replace(r'\\\\N', np.nan, regex=True, inplace=True)  # Replace invalid strings\n",
    "data.fillna(0, inplace=True)  # Replace NaN values with 0 (or use appropriate imputation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculate_monthly_orders_with_sarima(data):\n",
    "    \"\"\"\n",
    "    Groups transactional data by month to calculate the number of unique orders.\n",
    "    Applies SARIMA model for forecasting and evaluates its performance.\n",
    "    Forecasts for the next five months and the next two months.\n",
    "    \"\"\"\n",
    "    # Step 1: Preprocessing\n",
    "    data['order_date'] = pd.to_datetime(data['order_date'], format='%d.%m.%Y')\n",
    "    data['year_month'] = data['order_date'].dt.to_period('M')\n",
    "    monthly_orders = (\n",
    "        data.groupby('year_month')['Customer Order Code']\n",
    "        .nunique()\n",
    "        .reset_index(name='distinct_orders')\n",
    "    )\n",
    "\n",
    "    # Prepare data for SARIMA\n",
    "    monthly_orders['year_month'] = pd.to_datetime(monthly_orders['year_month'].astype(str))\n",
    "    monthly_orders.set_index('year_month', inplace=True)\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    train_size = int(len(monthly_orders)) - 5\n",
    "    train_data = monthly_orders.iloc[:train_size]\n",
    "    test_data = monthly_orders.iloc[train_size:]\n",
    "\n",
    "    # Step 2: Fit SARIMA model\n",
    "    sarima_model = SARIMAX(train_data['distinct_orders'],\n",
    "                           order=(1, 0, 2),\n",
    "                           seasonal_order=(1, 1, 1, 12))\n",
    "    sarima_result = sarima_model.fit(disp=False)\n",
    "\n",
    "    # Step 3: Forecast for the test set (existing data)\n",
    "    forecast_test = sarima_result.forecast(steps=len(test_data))\n",
    "    \n",
    "    # Step 4: Forecast for future months\n",
    "    future_forecast_5_months = sarima_result.forecast(steps=5)\n",
    "\n",
    "\n",
    "    return future_forecast_5_months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def classify_and_evaluate_product_demand(data, months=5):\n",
    "    \"\"\"\n",
    "    Prepares data for a classification model by encoding features, trains a logistic regression model,\n",
    "    and evaluates it. Forecasts demand for the next specified number of months.\n",
    "    \"\"\"\n",
    "    # Add seasonality based on the order date\n",
    "    def get_season(month):\n",
    "        if month in [12, 1, 2]:\n",
    "            return 'Winter'\n",
    "        elif month in [3, 4, 5]:\n",
    "            return 'Spring'\n",
    "        elif month in [6, 7, 8]:\n",
    "            return 'Summer'\n",
    "        else:\n",
    "            return 'Fall'\n",
    "\n",
    "    data['order_date'] = pd.to_datetime(data['order_date'], format='%d.%m.%Y')\n",
    "    data['Season'] = data['order_date'].dt.month.apply(get_season)\n",
    "\n",
    "    # Encode categorical variables\n",
    "    encoded_data = pd.get_dummies(data, columns=['Season', 'Customer Country Code','Curr', 'Route', 'order_type'], drop_first=True)\n",
    "\n",
    "    # Define features and target variable\n",
    "    X = encoded_data.drop(columns=['Product Code', 'year_month', 'order_date', 'requested_delivery_date', 'Customer Order Code', 'Description'])\n",
    "    y = encoded_data['Product Code']\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train a logistic regression model\n",
    "    logistic_model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000, random_state=42)\n",
    "    logistic_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred_logistic = logistic_model.predict(X_test)\n",
    "\n",
    "    # Forecast demand for the next `months`\n",
    "    future_forecast_demand = logistic_model.predict(X_test.sample(n=months, random_state=42))\n",
    "\n",
    "    return y_pred_logistic,future_forecast_demand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def simulate_quantity_demand(data, n_months=5):\n",
    "    \"\"\"\n",
    "    Recalculates 25th and 75th percentiles for each product and simulates demand for the next n months.\n",
    "    :param data: Pandas DataFrame with columns 'Product Code' and 'items'.\n",
    "    :param n_months: Number of months to simulate demand for.\n",
    "    :return: DataFrame with simulated demand for each product.\n",
    "    \"\"\"\n",
    "    # Recalculate percentiles for each product\n",
    "    # Ensure the 'items' column is numeric\n",
    "    data['items'] = pd.to_numeric(data['items'], errors='coerce')\n",
    "    # Drop rows with NaN in the 'items' column after conversion\n",
    "    data = data.dropna(subset=['items'])\n",
    "    # Group by 'Product Code' and calculate the quantiles\n",
    "    quantity_bounds = data.groupby('Product Code')['items'].quantile([0.25, 0.5, 0.75]).unstack().reset_index()\n",
    "    # Rename the columns for clarity\n",
    "    quantity_bounds.columns = ['Product Code', '25th Percentile','50th Percentile', '75th Percentile']\n",
    "\n",
    "\n",
    "    # Simulate demand for the next n_months\n",
    "    simulated_demand = []\n",
    "\n",
    "    for _, row in quantity_bounds.iterrows():\n",
    "        mean_quantity = row['50th Percentile']\n",
    "        std_dev_quantity = (row['75th Percentile'] - row['25th Percentile']) / 6  # Assuming normal distribution\n",
    "        product_demand = np.random.normal(mean_quantity, std_dev_quantity, n_months).clip(0)  # Ensure no negative values\n",
    "        simulated_demand.append(product_demand)\n",
    "\n",
    "    # Create a DataFrame for the simulated demand\n",
    "    simulated_demand_data = pd.DataFrame(\n",
    "        simulated_demand,\n",
    "        columns=[f\"Month {i+1}\" for i in range(n_months)],\n",
    "        index=quantity_bounds['Product Code']\n",
    "    ).reset_index()\n",
    "\n",
    "    # Rename columns for clarity\n",
    "    simulated_demand_data.rename(columns={'index': 'Product Code'}, inplace=True)\n",
    "\n",
    "    return simulated_demand_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer Order Code</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.420000e+03</td>\n",
       "      <td>2420.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.200672e+09</td>\n",
       "      <td>1162.976624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.004408e+05</td>\n",
       "      <td>2560.595118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.200435e+09</td>\n",
       "      <td>-0.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.200614e+09</td>\n",
       "      <td>33.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.200711e+09</td>\n",
       "      <td>70.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.200729e+09</td>\n",
       "      <td>1363.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.201062e+09</td>\n",
       "      <td>38937.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Customer Order Code         value\n",
       "count         2.420000e+03   2420.000000\n",
       "mean          3.200672e+09   1162.976624\n",
       "std           1.004408e+05   2560.595118\n",
       "min           3.200435e+09     -0.030000\n",
       "25%           3.200614e+09     33.030000\n",
       "50%           3.200711e+09     70.490000\n",
       "75%           3.200729e+09   1363.200000\n",
       "max           3.201062e+09  38937.500000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Drop rows with NaN in 'lead_time'\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlead_time\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear_month\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder_date\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mto_period(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Group by 'Product Code' and calculate quantiles\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Drop rows with NaN in 'lead_time'\n",
    "df = df.dropna(subset=['lead_time'])\n",
    "    \n",
    "df['year_month'] = df['order_date'].dt.to_period('M')\n",
    "# Group by 'Product Code' and calculate quantiles\n",
    "lead_time_bounds = df.groupby('year_month')['lead_time'].quantile([0.05, 0.5, 0.95]).unstack().reset_index()\n",
    "\n",
    "lead_time_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_month</th>\n",
       "      <th>5th Percentile</th>\n",
       "      <th>50th Percentile</th>\n",
       "      <th>95th Percentile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-07</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>7.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-08</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>6.866667</td>\n",
       "      <td>9.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-09</td>\n",
       "      <td>5.970000</td>\n",
       "      <td>6.150000</td>\n",
       "      <td>8.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-10</td>\n",
       "      <td>5.266667</td>\n",
       "      <td>6.366667</td>\n",
       "      <td>7.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-11</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>7.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2009-12</td>\n",
       "      <td>6.191667</td>\n",
       "      <td>8.533333</td>\n",
       "      <td>11.363333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2010-01</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>7.466667</td>\n",
       "      <td>8.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2010-02</td>\n",
       "      <td>5.186667</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.263333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2010-03</td>\n",
       "      <td>4.856667</td>\n",
       "      <td>6.133333</td>\n",
       "      <td>8.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2010-04</td>\n",
       "      <td>2.966667</td>\n",
       "      <td>4.266667</td>\n",
       "      <td>7.153333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2010-05</td>\n",
       "      <td>6.433333</td>\n",
       "      <td>6.433333</td>\n",
       "      <td>6.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2010-06</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>2.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2010-12</td>\n",
       "      <td>8.733333</td>\n",
       "      <td>9.266667</td>\n",
       "      <td>11.996667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2011-01</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>6.866667</td>\n",
       "      <td>8.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2011-02</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>6.733333</td>\n",
       "      <td>8.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2011-03</td>\n",
       "      <td>5.466667</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>8.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2011-04</td>\n",
       "      <td>4.680000</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>7.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2011-05</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>4.508333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2011-06</td>\n",
       "      <td>2.366667</td>\n",
       "      <td>8.433333</td>\n",
       "      <td>9.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2011-07</td>\n",
       "      <td>7.233333</td>\n",
       "      <td>7.966667</td>\n",
       "      <td>10.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2011-08</td>\n",
       "      <td>5.325000</td>\n",
       "      <td>7.066667</td>\n",
       "      <td>9.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2011-09</td>\n",
       "      <td>4.266667</td>\n",
       "      <td>6.083333</td>\n",
       "      <td>9.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2011-10</td>\n",
       "      <td>3.956667</td>\n",
       "      <td>4.466667</td>\n",
       "      <td>6.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2011-11</td>\n",
       "      <td>1.193333</td>\n",
       "      <td>1.533333</td>\n",
       "      <td>5.358333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2012-01</td>\n",
       "      <td>2.766667</td>\n",
       "      <td>2.766667</td>\n",
       "      <td>12.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2012-04</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year_month  5th Percentile  50th Percentile  95th Percentile\n",
       "0     2009-07        6.166667         6.500000         7.900000\n",
       "1     2009-08        5.700000         6.866667         9.833333\n",
       "2     2009-09        5.970000         6.150000         8.666667\n",
       "3     2009-10        5.266667         6.366667         7.866667\n",
       "4     2009-11        7.700000         7.700000         7.700000\n",
       "5     2009-12        6.191667         8.533333        11.363333\n",
       "6     2010-01        5.666667         7.466667         8.610000\n",
       "7     2010-02        5.186667         7.000000         8.263333\n",
       "8     2010-03        4.856667         6.133333         8.466667\n",
       "9     2010-04        2.966667         4.266667         7.153333\n",
       "10    2010-05        6.433333         6.433333         6.433333\n",
       "11    2010-06        2.833333         2.833333         2.833333\n",
       "12    2010-12        8.733333         9.266667        11.996667\n",
       "13    2011-01        6.666667         6.866667         8.366667\n",
       "14    2011-02        5.400000         6.733333         8.100000\n",
       "15    2011-03        5.466667         6.166667         8.466667\n",
       "16    2011-04        4.680000         5.833333         7.466667\n",
       "17    2011-05        3.200000         3.700000         4.508333\n",
       "18    2011-06        2.366667         8.433333         9.100000\n",
       "19    2011-07        7.233333         7.966667        10.900000\n",
       "20    2011-08        5.325000         7.066667         9.100000\n",
       "21    2011-09        4.266667         6.083333         9.020000\n",
       "22    2011-10        3.956667         4.466667         6.966667\n",
       "23    2011-11        1.193333         1.533333         5.358333\n",
       "24    2012-01        2.766667         2.766667        12.500000\n",
       "25    2012-04        6.000000         6.000000         6.000000"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename columns for clarity\n",
    "lead_time_bounds.columns = ['year_month', '5th Percentile', '50th Percentile', '95th Percentile']\n",
    "\n",
    "lead_time_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_leadtime = {}\n",
    "\n",
    "for _, row in lead_time_bounds.iterrows():\n",
    "        q25 = row['5th Percentile']\n",
    "        q75 = row['95th Percentile']\n",
    "        \n",
    "        # Calculate mean and std\n",
    "        mean = row['50th Percentile']\n",
    "        std_dev = (q75 - q25) / 1.35\n",
    "        \n",
    "        # Generate samples\n",
    "        samples = np.random.normal(loc=mean, scale=std_dev, size=1).clip(min=0)\n",
    "        \n",
    "        # Store in dictionary using the year-month as key\n",
    "        simulated_leadtime[row['year_month']] = samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year_month  Lead Time\n",
      "0     2009-07   6.691526\n",
      "1     2009-08   4.882458\n",
      "2     2009-09   1.543551\n",
      "3     2009-10   5.469893\n",
      "4     2009-11   7.700000\n",
      "5     2009-12   2.998189\n",
      "6     2010-01   5.071348\n",
      "7     2010-02   7.351076\n",
      "8     2010-03   4.273749\n",
      "9     2010-04   3.883436\n",
      "10    2010-05   6.433333\n",
      "11    2010-06   2.833333\n",
      "12    2010-12  13.612714\n",
      "13    2011-01   6.757844\n",
      "14    2011-02   7.342526\n",
      "15    2011-03   3.616200\n",
      "16    2011-04   7.512580\n",
      "17    2011-05   1.629396\n",
      "18    2011-06   9.176285\n",
      "19    2011-07  11.037648\n",
      "20    2011-08   5.190213\n",
      "21    2011-09   8.355481\n",
      "22    2011-10   3.962408\n",
      "23    2011-11   0.577703\n",
      "24    2012-01   5.065594\n",
      "25    2012-04   6.000000\n"
     ]
    }
   ],
   "source": [
    "# Convert the simulated_leadtime dictionary to a DataFrame\n",
    "simulated_leadtime_df = pd.DataFrame.from_dict(\n",
    "    simulated_leadtime, orient='index'\n",
    ").reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "simulated_leadtime_df.columns = ['year_month'] + [f\"Lead Time\" ]\n",
    "\n",
    "# Display the DataFrame\n",
    "print(simulated_leadtime_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def calculate_and_simulate_lead_time(data, months=5, n_samples=1):\n",
    "    \"\"\"\n",
    "    Calculate lead time bounds and simulate lead time using normal distribution.\n",
    "\n",
    "    Parameters:\n",
    "        data (pd.DataFrame): Input data containing 'order_date' and 'requested_delivery_date'.\n",
    "        months (int): Number of months to filter data for lead time calculation.\n",
    "        n_samples (int): Number of lead time samples to generate per month.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Simulated lead times for the filtered months.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 2: Convert date columns and calculate lead time in months\n",
    "    data['order_date'] = pd.to_datetime(data['order_date'], format='%d.%m.%Y')\n",
    "    data['requested_delivery_date'] = pd.to_datetime(data['requested_delivery_date'], format='%d.%m.%Y')\n",
    "    data['lead_time'] = (data['requested_delivery_date'] - data['order_date']).dt.days / 30\n",
    "\n",
    "    # Step 3: Drop rows with NaN in 'lead_time'\n",
    "    data = data.dropna(subset=['lead_time'])\n",
    "\n",
    "    # Step 4: Group by 'year_month' and calculate lead time quantiles\n",
    "    data['year_month'] = data['order_date'].dt.to_period('M')\n",
    "    lead_time_bounds = data.groupby('year_month')['lead_time'].quantile([0.05, 0.5, 0.95]).unstack().reset_index()\n",
    "    lead_time_bounds.columns = ['year_month', '5th Percentile', '50th Percentile', '95th Percentile']\n",
    "\n",
    "    # Step 5: Simulate lead time using normal distribution\n",
    "    simulated_leadtime = {}\n",
    "    for _, row in lead_time_bounds.iterrows():\n",
    "        q05 = row['5th Percentile']\n",
    "        q95 = row['95th Percentile']\n",
    "\n",
    "        # Calculate mean and std deviation\n",
    "        mean = row['50th Percentile']\n",
    "        std_dev = (q05 - q95) / 1.35\n",
    "\n",
    "        # Generate samples\n",
    "        samples = np.random.normal(mean, scale=std_dev, size=n_samples).clip(min=0)\n",
    "\n",
    "        # Store in dictionary\n",
    "        simulated_leadtime[row['year_month']] = samples\n",
    "\n",
    "    # Step 6: Convert simulated leadtime dictionary to DataFrame\n",
    "# Convert the simulated_leadtime dictionary to a DataFrame\n",
    "    simulated_leadtime_df = pd.DataFrame.from_dict(\n",
    "        simulated_leadtime, orient='index'\n",
    "    ).reset_index()\n",
    "\n",
    "    # Rename columns for clarity\n",
    "    simulated_leadtime_df.columns = ['year_month'] + [f\"Lead Time\" ]\n",
    "\n",
    "    return simulated_leadtime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "scale < 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m calculate_and_simulate_lead_time(data)\n",
      "Cell \u001b[1;32mIn[22], line 41\u001b[0m, in \u001b[0;36mcalculate_and_simulate_lead_time\u001b[1;34m(data, months, n_samples)\u001b[0m\n\u001b[0;32m     38\u001b[0m std_dev \u001b[38;5;241m=\u001b[39m (q05 \u001b[38;5;241m-\u001b[39m q95) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1.35\u001b[39m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Generate samples\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m samples \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(mean, scale\u001b[38;5;241m=\u001b[39mstd_dev, size\u001b[38;5;241m=\u001b[39mn_samples)\u001b[38;5;241m.\u001b[39mclip(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Store in dictionary\u001b[39;00m\n\u001b[0;32m     44\u001b[0m simulated_leadtime[row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear_month\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m samples\n",
      "File \u001b[1;32mmtrand.pyx:1540\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.normal\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_common.pyx:616\u001b[0m, in \u001b[0;36mnumpy.random._common.cont\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_common.pyx:422\u001b[0m, in \u001b[0;36mnumpy.random._common.check_constraint\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: scale < 0"
     ]
    }
   ],
   "source": [
    "calculate_and_simulate_lead_time(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def consolidated_mc_function(data):\n",
    "    \"\"\"\n",
    "    Consolidates the outputs of four individual functions into a single table.\n",
    "\n",
    "    :param data: Pandas DataFrame containing the necessary input data.\n",
    "    :return: Pandas DataFrame summarizing the results of all calculations.\n",
    "    \"\"\"\n",
    "    # Call each individual function\n",
    "    forecast_5_months, forecast_2_months, mape_test = calculate_monthly_orders_with_sarima(data)\n",
    "    logistic_predictions, forecast_demand = classify_and_evaluate_product_demand(data)\n",
    "    simulated_demand_data = simulate_quantity_demand(data)\n",
    "    simulated_lead_time = calculate_and_simulate_lead_time(data)\n",
    "\n",
    "    # Compile results into a dictionary\n",
    "    results_dict = {\n",
    "        \"SARIMA Forecast (5 months)\": forecast_5_months,\n",
    "        \"SARIMA Forecast (2 months)\": forecast_2_months,\n",
    "        \"MAPE Test\": mape_test,\n",
    "        \"Logistic Predictions\": logistic_predictions,\n",
    "        \"Forecasted Demand (Logistic)\": forecast_demand,\n",
    "        \"Simulated Demand\": simulated_demand_data,\n",
    "        \"Simulated Lead Time\": simulated_lead_time\n",
    "    }\n",
    "\n",
    "    # Convert the dictionary to a DataFrame for better presentation\n",
    "    results_df = pd.DataFrame.from_dict(results_dict, orient='index').transpose()\n",
    "    \n",
    "    return results_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
